

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8">
  <meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>torchsar.module.layers package &mdash; TorchSAR 1.0 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" type="text/css" />
  <link rel="stylesheet" href="_static/katex-math.css" type="text/css" />

  
  
  
  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js"></script>
        <script src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js"></script>
        <script src="_static/katex_autorenderer.js"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="torchsar.module.loss package" href="torchsar.module.loss.html" />
    <link rel="prev" title="torchsar.module.imaging package" href="torchsar.module.imaging.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home" alt="Documentation Home"> TorchSAR
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="getstarted.html">Get Started</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="modules.html">torchsar</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="setup.html">setup module</a></li>
<li class="toctree-l2 current"><a class="reference internal" href="torchsar.html">torchsar package</a><ul class="current">
<li class="toctree-l3 current"><a class="reference internal" href="torchsar.html#subpackages">Subpackages</a><ul class="current">
<li class="toctree-l4"><a class="reference internal" href="torchsar.autofocus.html">torchsar.autofocus package</a></li>
<li class="toctree-l4"><a class="reference internal" href="torchsar.base.html">torchsar.base package</a></li>
<li class="toctree-l4"><a class="reference internal" href="torchsar.calibration.html">torchsar.calibration package</a></li>
<li class="toctree-l4"><a class="reference internal" href="torchsar.dsp.html">torchsar.dsp package</a></li>
<li class="toctree-l4"><a class="reference internal" href="torchsar.evaluation.html">torchsar.evaluation package</a></li>
<li class="toctree-l4"><a class="reference internal" href="torchsar.imaging.html">torchsar.imaging package</a></li>
<li class="toctree-l4"><a class="reference internal" href="torchsar.layerfunction.html">torchsar.layerfunction package</a></li>
<li class="toctree-l4"><a class="reference internal" href="torchsar.misc.html">torchsar.misc package</a></li>
<li class="toctree-l4 current"><a class="reference internal" href="torchsar.module.html">torchsar.module package</a></li>
<li class="toctree-l4"><a class="reference internal" href="torchsar.sarcfg.html">torchsar.sarcfg package</a></li>
<li class="toctree-l4"><a class="reference internal" href="torchsar.sharing.html">torchsar.sharing package</a></li>
<li class="toctree-l4"><a class="reference internal" href="torchsar.simulation.html">torchsar.simulation package</a></li>
<li class="toctree-l4"><a class="reference internal" href="torchsar.sparse.html">torchsar.sparse package</a></li>
<li class="toctree-l4"><a class="reference internal" href="torchsar.utils.html">torchsar.utils package</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="torchsar.html#module-torchsar">Module contents</a></li>
</ul>
</li>
</ul>
</li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">TorchSAR</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="modules.html">torchsar</a> &raquo;</li>
        
          <li><a href="torchsar.html">torchsar package</a> &raquo;</li>
        
          <li><a href="torchsar.module.html">torchsar.module package</a> &raquo;</li>
        
      <li>torchsar.module.layers package</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/torchsar.module.layers.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <section id="torchsar-module-layers-package">
<h1>torchsar.module.layers package<a class="headerlink" href="#torchsar-module-layers-package" title="Permalink to this headline">¶</a></h1>
<section id="submodules">
<h2>Submodules<a class="headerlink" href="#submodules" title="Permalink to this headline">¶</a></h2>
</section>
<section id="module-torchsar.module.layers.complex_layers">
<span id="torchsar-module-layers-complex-layers-module"></span><h2>torchsar.module.layers.complex_layers module<a class="headerlink" href="#module-torchsar.module.layers.complex_layers" title="Permalink to this headline">¶</a></h2>
<p>Created on Tue Mar 19 10:30:02 2019</p>
<p>&#64;author: Sebastien M. Popoff</p>
<p>Based on <a class="reference external" href="https://openreview.net/forum?id=H1T2hmZAb">https://openreview.net/forum?id=H1T2hmZAb</a></p>
<dl class="class">
<dt id="torchsar.module.layers.complex_layers.ComplexBatchNorm1d">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">ComplexBatchNorm1d</code><span class="sig-paren">(</span><em class="sig-param">num_features</em>, <em class="sig-param">eps=1e-05</em>, <em class="sig-param">momentum=0.1</em>, <em class="sig-param">affine=True</em>, <em class="sig-param">track_running_stats=True</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexBatchNorm1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torchsar.module.layers.complex_layers._ComplexBatchNorm</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.ComplexBatchNorm1d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexBatchNorm1d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.ComplexBatchNorm1d.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexBatchNorm1d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.ComplexBatchNorm2d">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">ComplexBatchNorm2d</code><span class="sig-paren">(</span><em class="sig-param">num_features</em>, <em class="sig-param">eps=1e-05</em>, <em class="sig-param">momentum=0.1</em>, <em class="sig-param">affine=True</em>, <em class="sig-param">track_running_stats=True</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexBatchNorm2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torchsar.module.layers.complex_layers._ComplexBatchNorm</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.ComplexBatchNorm2d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexBatchNorm2d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.ComplexBatchNorm2d.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexBatchNorm2d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.ComplexConv1">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">ComplexConv1</code><span class="sig-paren">(</span><em class="sig-param">axis</em>, <em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size=3</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">groups=1</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">padding_mode='zeros'</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexConv1" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.ComplexConv1.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">Xr</em>, <em class="sig-param">Xi</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexConv1.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.ComplexConv1.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexConv1.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.ComplexConv1d">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">ComplexConv1d</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size=3</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">groups=1</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">padding_mode='zeros'</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexConv1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.ComplexConv1d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexConv1d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.ComplexConv1d.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexConv1d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.ComplexConv2">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">ComplexConv2</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size=3</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">groups=1</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">padding_mode='zeros'</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexConv2" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.ComplexConv2.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">Xr</em>, <em class="sig-param">Xi</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexConv2.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.ComplexConv2.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexConv2.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.ComplexConv2d">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">ComplexConv2d</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size=3</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">groups=1</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">padding_mode='zeros'</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexConv2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.ComplexConv2d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexConv2d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.ComplexConv2d.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexConv2d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.ComplexConvTranspose1d">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">ComplexConvTranspose1d</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">output_padding=0</em>, <em class="sig-param">groups=1</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">padding_mode='zeros'</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexConvTranspose1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.ComplexConvTranspose1d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexConvTranspose1d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.ComplexConvTranspose1d.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexConvTranspose1d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.ComplexConvTranspose2d">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">ComplexConvTranspose2d</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">output_padding=0</em>, <em class="sig-param">groups=1</em>, <em class="sig-param">bias=True</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">padding_mode='zeros'</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexConvTranspose2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.ComplexConvTranspose2d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexConvTranspose2d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.ComplexConvTranspose2d.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexConvTranspose2d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.ComplexDropout">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">ComplexDropout</code><span class="sig-paren">(</span><em class="sig-param">p=0.5</em>, <em class="sig-param">inplace=False</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexDropout" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.ComplexDropout.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexDropout.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.ComplexDropout.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexDropout.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.ComplexDropout2d">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">ComplexDropout2d</code><span class="sig-paren">(</span><em class="sig-param">p=0.5</em>, <em class="sig-param">inplace=False</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexDropout2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.ComplexDropout2d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexDropout2d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.ComplexDropout2d.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexDropout2d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.ComplexLeakyReLU">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">ComplexLeakyReLU</code><span class="sig-paren">(</span><em class="sig-param">negative_slope=(0.01</em>, <em class="sig-param">0.01)</em>, <em class="sig-param">inplace=False</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexLeakyReLU" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.ComplexLeakyReLU.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexLeakyReLU.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.ComplexLeakyReLU.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexLeakyReLU.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.ComplexLinear">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">ComplexLinear</code><span class="sig-paren">(</span><em class="sig-param">in_features</em>, <em class="sig-param">out_features</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexLinear" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.ComplexLinear.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexLinear.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.ComplexLinear.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexLinear.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.ComplexMaxPool1">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">ComplexMaxPool1</code><span class="sig-paren">(</span><em class="sig-param">axis</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">stride=None</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">return_indices=False</em>, <em class="sig-param">ceil_mode=False</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexMaxPool1" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.ComplexMaxPool1.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">Xr</em>, <em class="sig-param">Xi</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexMaxPool1.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.ComplexMaxPool1.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexMaxPool1.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.ComplexMaxPool1d">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">ComplexMaxPool1d</code><span class="sig-paren">(</span><em class="sig-param">kernel_size</em>, <em class="sig-param">stride=None</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">return_indices=False</em>, <em class="sig-param">ceil_mode=False</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexMaxPool1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.ComplexMaxPool1d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexMaxPool1d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.ComplexMaxPool1d.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexMaxPool1d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.ComplexMaxPool2">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">ComplexMaxPool2</code><span class="sig-paren">(</span><em class="sig-param">kernel_size</em>, <em class="sig-param">stride=None</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">return_indices=False</em>, <em class="sig-param">ceil_mode=False</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexMaxPool2" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.ComplexMaxPool2.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">Xr</em>, <em class="sig-param">Xi</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexMaxPool2.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.ComplexMaxPool2.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexMaxPool2.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.ComplexMaxPool2d">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">ComplexMaxPool2d</code><span class="sig-paren">(</span><em class="sig-param">kernel_size</em>, <em class="sig-param">stride=None</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">return_indices=False</em>, <em class="sig-param">ceil_mode=False</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexMaxPool2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.ComplexMaxPool2d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexMaxPool2d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.ComplexMaxPool2d.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexMaxPool2d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.ComplexReLU">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">ComplexReLU</code><span class="sig-paren">(</span><em class="sig-param">inplace=False</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexReLU" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.ComplexReLU.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexReLU.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.ComplexReLU.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexReLU.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.ComplexSequential">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">ComplexSequential</code><span class="sig-paren">(</span><em class="sig-param">*args</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexSequential" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.container.Sequential</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.ComplexSequential.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexSequential.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.ComplexSequential.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexSequential.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.ComplexSoftShrink">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">ComplexSoftShrink</code><span class="sig-paren">(</span><em class="sig-param">alpha=0.5</em>, <em class="sig-param">caxis=None</em>, <em class="sig-param">inplace=False</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexSoftShrink" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.ComplexSoftShrink.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">alpha=None</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexSoftShrink.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.ComplexSoftShrink.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexSoftShrink.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.ComplexUpsample">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">ComplexUpsample</code><span class="sig-paren">(</span><em class="sig-param">size=None</em>, <em class="sig-param">scale_factor=None</em>, <em class="sig-param">mode='nearest'</em>, <em class="sig-param">align_corners=None</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexUpsample" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.ComplexUpsample.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexUpsample.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.ComplexUpsample.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.ComplexUpsample.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.NaiveComplexBatchNorm1d">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">NaiveComplexBatchNorm1d</code><span class="sig-paren">(</span><em class="sig-param">num_features</em>, <em class="sig-param">eps=1e-05</em>, <em class="sig-param">momentum=0.1</em>, <em class="sig-param">affine=True</em>, <em class="sig-param">track_running_stats=True</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.NaiveComplexBatchNorm1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Naive approach to complex batch norm, perform batch norm independently on real and imaginary part.</p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.NaiveComplexBatchNorm1d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.NaiveComplexBatchNorm1d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.NaiveComplexBatchNorm1d.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.NaiveComplexBatchNorm1d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.NaiveComplexBatchNorm2d">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">NaiveComplexBatchNorm2d</code><span class="sig-paren">(</span><em class="sig-param">num_features</em>, <em class="sig-param">eps=1e-05</em>, <em class="sig-param">momentum=0.1</em>, <em class="sig-param">affine=True</em>, <em class="sig-param">track_running_stats=True</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.NaiveComplexBatchNorm2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<p>Naive approach to complex batch norm, perform batch norm independently on real and imaginary part.</p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.NaiveComplexBatchNorm2d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.NaiveComplexBatchNorm2d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.NaiveComplexBatchNorm2d.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.NaiveComplexBatchNorm2d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.complex_layers.SoftShrink">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.complex_layers.</code><code class="sig-name descname">SoftShrink</code><span class="sig-paren">(</span><em class="sig-param">alpha=0.5</em>, <em class="sig-param">inplace=False</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.SoftShrink" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.complex_layers.SoftShrink.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">input</em>, <em class="sig-param">alpha=None</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.complex_layers.SoftShrink.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.complex_layers.SoftShrink.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.complex_layers.SoftShrink.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-torchsar.module.layers.consistency_layers">
<span id="torchsar-module-layers-consistency-layers-module"></span><h2>torchsar.module.layers.consistency_layers module<a class="headerlink" href="#module-torchsar.module.layers.consistency_layers" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchsar.module.layers.consistency_layers.DataConsistency2d">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.consistency_layers.</code><code class="sig-name descname">DataConsistency2d</code><span class="sig-paren">(</span><em class="sig-param">ftaxis=(-2</em>, <em class="sig-param">-1)</em>, <em class="sig-param">mixrate=1.0</em>, <em class="sig-param">isfft=True</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.consistency_layers.DataConsistency2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.consistency_layers.DataConsistency2d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em>, <em class="sig-param">y</em>, <em class="sig-param">mask</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.consistency_layers.DataConsistency2d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.consistency_layers.DataConsistency2d.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.consistency_layers.DataConsistency2d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-torchsar.module.layers.fft_layers">
<span id="torchsar-module-layers-fft-layers-module"></span><h2>torchsar.module.layers.fft_layers module<a class="headerlink" href="#module-torchsar.module.layers.fft_layers" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchsar.module.layers.fft_layers.FFTLayer1d">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.fft_layers.</code><code class="sig-name descname">FFTLayer1d</code><span class="sig-paren">(</span><em class="sig-param">nfft=None</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.fft_layers.FFTLayer1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.fft_layers.FFTLayer1d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.fft_layers.FFTLayer1d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.fft_layers.FFTLayer1d.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.fft_layers.FFTLayer1d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-torchsar.module.layers.phase_convolution">
<span id="torchsar-module-layers-phase-convolution-module"></span><h2>torchsar.module.layers.phase_convolution module<a class="headerlink" href="#module-torchsar.module.layers.phase_convolution" title="Permalink to this headline">¶</a></h2>
<dl class="class">
<dt id="torchsar.module.layers.phase_convolution.ComplexPhaseConv1d">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.phase_convolution.</code><code class="sig-name descname">ComplexPhaseConv1d</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size=3</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">groups=1</em>, <em class="sig-param">bias=None</em>, <em class="sig-param">padding_mode='zeros'</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.phase_convolution.ComplexPhaseConv1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.phase_convolution.ComplexPhaseConv1d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.phase_convolution.ComplexPhaseConv1d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.phase_convolution.ComplexPhaseConv1d.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.phase_convolution.ComplexPhaseConv1d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.phase_convolution.ComplexPhaseConv2d">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.phase_convolution.</code><code class="sig-name descname">ComplexPhaseConv2d</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size=3</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">groups=1</em>, <em class="sig-param">bias=None</em>, <em class="sig-param">padding_mode='zeros'</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.phase_convolution.ComplexPhaseConv2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.phase_convolution.ComplexPhaseConv2d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.phase_convolution.ComplexPhaseConv2d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.phase_convolution.ComplexPhaseConv2d.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.phase_convolution.ComplexPhaseConv2d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.phase_convolution.ComplexPhaseConvTranspose1d">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.phase_convolution.</code><code class="sig-name descname">ComplexPhaseConvTranspose1d</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">output_padding=0</em>, <em class="sig-param">groups=1</em>, <em class="sig-param">bias=None</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">padding_mode='zeros'</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.phase_convolution.ComplexPhaseConvTranspose1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.phase_convolution.ComplexPhaseConvTranspose1d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.phase_convolution.ComplexPhaseConvTranspose1d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.phase_convolution.ComplexPhaseConvTranspose1d.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.phase_convolution.ComplexPhaseConvTranspose1d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.phase_convolution.ComplexPhaseConvTranspose2d">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.phase_convolution.</code><code class="sig-name descname">ComplexPhaseConvTranspose2d</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">output_padding=0</em>, <em class="sig-param">groups=1</em>, <em class="sig-param">bias=None</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">padding_mode='zeros'</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.phase_convolution.ComplexPhaseConvTranspose2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.phase_convolution.ComplexPhaseConvTranspose2d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.phase_convolution.ComplexPhaseConvTranspose2d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.phase_convolution.ComplexPhaseConvTranspose2d.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.phase_convolution.ComplexPhaseConvTranspose2d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.phase_convolution.PhaseConv1d">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.phase_convolution.</code><code class="sig-name descname">PhaseConv1d</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size=3</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">groups=1</em>, <em class="sig-param">bias=None</em>, <em class="sig-param">padding_mode='zeros'</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.phase_convolution.PhaseConv1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.phase_convolution.PhaseConv1d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.phase_convolution.PhaseConv1d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.phase_convolution.PhaseConv1d.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.phase_convolution.PhaseConv1d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.phase_convolution.PhaseConv2d">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.phase_convolution.</code><code class="sig-name descname">PhaseConv2d</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size=3</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">groups=1</em>, <em class="sig-param">bias=None</em>, <em class="sig-param">padding_mode='zeros'</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.phase_convolution.PhaseConv2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.phase_convolution.PhaseConv2d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.phase_convolution.PhaseConv2d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.phase_convolution.PhaseConv2d.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.phase_convolution.PhaseConv2d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.phase_convolution.PhaseConvTranspose1d">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.phase_convolution.</code><code class="sig-name descname">PhaseConvTranspose1d</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">output_padding=0</em>, <em class="sig-param">groups=1</em>, <em class="sig-param">bias=None</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">padding_mode='zeros'</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.phase_convolution.PhaseConvTranspose1d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.phase_convolution.PhaseConvTranspose1d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.phase_convolution.PhaseConvTranspose1d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.phase_convolution.PhaseConvTranspose1d.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.phase_convolution.PhaseConvTranspose1d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

<dl class="class">
<dt id="torchsar.module.layers.phase_convolution.PhaseConvTranspose2d">
<em class="property">class </em><code class="sig-prename descclassname">torchsar.module.layers.phase_convolution.</code><code class="sig-name descname">PhaseConvTranspose2d</code><span class="sig-paren">(</span><em class="sig-param">in_channels</em>, <em class="sig-param">out_channels</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">stride=1</em>, <em class="sig-param">padding=0</em>, <em class="sig-param">output_padding=0</em>, <em class="sig-param">groups=1</em>, <em class="sig-param">bias=None</em>, <em class="sig-param">dilation=1</em>, <em class="sig-param">padding_mode='zeros'</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.phase_convolution.PhaseConvTranspose2d" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">torch.nn.modules.module.Module</span></code></p>
<dl class="method">
<dt id="torchsar.module.layers.phase_convolution.PhaseConvTranspose2d.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param">x</em><span class="sig-paren">)</span><a class="headerlink" href="#torchsar.module.layers.phase_convolution.PhaseConvTranspose2d.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Defines the computation performed at every call.</p>
<p>Should be overridden by all subclasses.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Although the recipe for forward pass needs to be defined within
this function, one should call the <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code> instance afterwards
instead of this since the former takes care of running the
registered hooks while the latter silently ignores them.</p>
</div>
</dd></dl>

<dl class="attribute">
<dt id="torchsar.module.layers.phase_convolution.PhaseConvTranspose2d.training">
<code class="sig-name descname">training</code><em class="property"> = None</em><a class="headerlink" href="#torchsar.module.layers.phase_convolution.PhaseConvTranspose2d.training" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

</dd></dl>

</section>
<section id="module-torchsar.module.layers">
<span id="module-contents"></span><h2>Module contents<a class="headerlink" href="#module-torchsar.module.layers" title="Permalink to this headline">¶</a></h2>
</section>
</section>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="torchsar.module.loss.html" class="btn btn-neutral float-right" title="torchsar.module.loss package" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="torchsar.module.imaging.html" class="btn btn-neutral float-left" title="torchsar.module.imaging package" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        
        &copy; Copyright 2017-2021, Zhi Liu, School of Artificial Intelligence, Xidian University

    </p>
  </div>
    
    
    
    Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>